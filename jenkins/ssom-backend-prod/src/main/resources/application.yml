spring:
  application:
    name: ssom-backend-prod

  profiles:
    active: prod

  datasource:
    url: ${SPRING_DATASOURCE_URL}
    username: ${SPRING_DATASOURCE_USERNAME}
    password: ${SPRING_DATASOURCE_PASSWORD}
    driver-class-name: com.mysql.cj.jdbc.Driver
    hikari:
      maximum-pool-size: 200
      minimum-idle: 10
      idle-timeout: 300000
      max-lifetime: 1800000
      connection-timeout: 3000
      validation-timeout: 3000
      leak-detection-threshold: 60000

  jpa:
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
        format_sql: true
        show_sql: true
        use_sql_comments: true
        jdbc:
          batch_size: 20
          time_zone: Asia/Seoul
        order_inserts: true
        order_updates: true
        batch_versioned_data: true
    show-sql: true

  data:
    redis:
      host: ${SPRING_DATA_REDIS_HOST}
      port: ${SPRING_DATA_REDIS_PORT}
      timeout: 2000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
          max-wait: -1ms
          time-between-eviction-runs: 60s

  # Kafka 설정
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}

    # Producer 설정
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: "1"                    # 리더만 확인 (성능과 안정성 균형)
      retries: 3                   # 재시도 횟수
      batch-size: 16384           # 배치 크기 (16KB)
      linger-ms: 5                # 배치 대기 시간 (5ms)
      buffer-memory: 33554432     # 버퍼 메모리 (32MB)
      compression-type: lz4       # 압축 타입
      request-timeout-ms: 30000   # 요청 타임아웃 (30초)
      delivery-timeout-ms: 120000 # 전체 전송 타임아웃 (2분)

    # Consumer 설정
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP:ssom-alert-consumer}
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
      auto-offset-reset: earliest  # 처음부터 읽기
      enable-auto-commit: false   # 수동 커밋
      max-poll-records: 10        # 한번에 처리할 레코드 수
      fetch-min-size: 1           # 최소 페치 크기
      fetch-max-wait: 500         # 최대 대기 시간 (500ms)
      heartbeat-interval: 3000    # 하트비트 간격 (3초)
      session-timeout: 30000      # 세션 타임아웃 (30초)
      properties:
        spring.deserializer.value.delegate.class: org.springframework.kafka.support.serializer.JsonDeserializer
        spring.json.trusted.packages: "kr.ssok.ssom.backend.domain.alert.dto.kafka"

    # 리스너 설정
    listener:
      concurrency: ${KAFKA_LISTENER_CONCURRENCY:10}  # 동시 처리 스레드 수
      ack-mode: manual_immediate                      # 수동 즉시 커밋
      missing-topics-fatal: false                     # 토픽 없어도 실행

jwt:
  secret: ${JWT_SECRET}
  access-token-validity-in-seconds: 1800
  refresh-token-validity-in-seconds: 604800
  sse-token-validity-in-seconds: 43200

security:
  whitelist:
    - "/api/users/login"
    - "/api/users/refresh"
    - "/api/users/signup"
    - "/api/users/phone"
    - "/api/users/phone/verify"
    - "/api/issues/webhook/github"
    - "/actuator/prometheus"
    - "/swagger-ui/**"
    - "/v3/api-docs/**"
    - "/error"
    - "/actuator/health/liveness"
    - "/actuator/health/readiness"
    - "/"
    - "/api/issues/github"

llm:
  api:
    url: ${LLM_API_URL}

github:
  api:
    token: ${GITHUB_TOKEN}
    owner: Team-SSOK
    repository: ssok-backend
  webhook:
    secret: ${GITHUB_WEBHOOK_SECRET}

# OpenSearch 설정
opensearch:
  scheme: ${OPENSEARCH_SCHEME:http}
  host: ${OPENSEARCH_HOST:kudong.kr}
  port: ${OPENSEARCH_PORT:55034}
  connect-timeout: ${OPENSEARCH_CONNECT_TIMEOUT:10}
  response-timeout: ${OPENSEARCH_RESPONSE_TIMEOUT:30}
  api:
    url: https://os.ssok.kr

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  prometheus:
    metrics:
      export:
        enabled: true

biometric:
  max-failure-attempts: 3
  failure-reset-time-minutes: 30
  device-block-time-minutes: 30
  timestamp-tolerance-ms: 300000
  max-biometric-hash-length: 500
  max-device-info-length: 1000

# FCM
firebase:
  configPath: "classpath:firebase/firebase-adminsdk-2.json"
  enabled: "true"
fcm:
  tokenTtlSeconds: "2592000"

# Alert Kafka 설정
alert:
  kafka:
    # 토픽 설정
    topics:
      alert-created: ${ALERT_CREATED_TOPIC:alert-created-topic}
      user-alert: ${USER_ALERT_TOPIC:user-alert-topic}
      dlq: ${ALERT_DLQ_TOPIC:alert-dlq-topic}

    # 토픽 생성 설정
    topic-config:
      alert-created:
        partitions: ${ALERT_CREATED_PARTITIONS:3}        # Alert 생성 토픽 파티션 수
      user-alert:
        partitions: ${USER_ALERT_PARTITIONS:10}          # 사용자 알림 토픽 파티션 수
      dlq:
        partitions: ${ALERT_DLQ_PARTITIONS:1}            # DLQ 토픽 파티션 수 (순서 보장을 위해 1개)
        retention-ms: ${DLQ_RETENTION_MS:2592000000}     # DLQ는 30일 보관 (더 길게)
      replication-factor: ${KAFKA_REPLICATION_FACTOR:1}  # 복제 팩터
      retention-ms: ${KAFKA_RETENTION_MS:604800000}      # 7일 보관

    # 처리 성능 설정
    processing:
      max-retry-attempts: 3           # 최대 재시도 횟수
      retry-delay-ms: 1000           # 재시도 지연 시간
      batch-size: 100                # 배치 처리 크기
      timeout-ms: 30000              # 처리 타임아웃

    # 모니터링 설정
    monitoring:
      enable-metrics: true           # 메트릭 수집 활성화
      log-processing-time: true      # 처리 시간 로깅
      alert-slow-processing-ms: 5000 # 느린 처리 알림 기준